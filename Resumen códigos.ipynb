{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repaso parcial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librer铆as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn\n",
    "%pip install seaborn\n",
    "%pip install --upgrade scikit-learn imbalanced-learn\n",
    "%pip install statsmodels\n",
    "%pip install mlxtend\n",
    "%pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer铆as b谩sicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizaci贸n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, confusion_matrix, classification_report, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "# Justicia\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap  # Para interpretabilidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar y procesar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar con los datos que te proporcionen\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Dividir en caracter铆sticas (X) y etiqueta (y)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Divisi贸n de los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar si es necesario\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelos de regresi贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base de regresi贸n\n",
    "reg_model = RandomForestRegressor(random_state=42)\n",
    "reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = reg_model.predict(X_test)\n",
    "\n",
    "# Evaluaci贸n\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# Interpretabilidad\n",
    "feature_importances = reg_model.feature_importances_\n",
    "plt.barh(X.columns, feature_importances)\n",
    "plt.title(\"Importancia de Caracter铆sticas\")\n",
    "plt.show()\n",
    "\n",
    "# SHAP para explicabilidad\n",
    "explainer = shap.Explainer(reg_model, X_test)\n",
    "shap_values = explainer(X_test)\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "\n",
    "# Visualizaci贸n Local: Predicci贸n individual\n",
    "shap.force_plot(explainer.expected_value, shap_values[0].values, X[0])\n",
    "\n",
    "# Visualizaci贸n de Dependencia\n",
    "shap.dependence_plot(\"RM\", shap_values.values, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Mean Absolute Error (MAE) mide el promedio de los errores absolutos entre las predicciones del modelo y los valores reales. \n",
    "\n",
    "- Escala: Est谩 en las mismas unidades que la variable objetivo.\n",
    "- Significado: Muestra el error promedio que comete el modelo al hacer predicciones.\n",
    "- Ejemplo: Si el MAE es 500 y la variable objetivo representa el precio de apartamentos en d贸lares, significa que, en promedio, el modelo se equivoca por $500 en cada predicci贸n.\n",
    "- Ventaja: F谩cil de interpretar.\n",
    "- Limitaci贸n: No penaliza grandes errores m谩s que peque帽os, ya que toma valores absolutos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Mean Squared Error (MSE) mide el promedio de los errores elevados al cuadrado\n",
    "\n",
    "- Escala: Est谩 en las unidades cuadradas de la variable objetivo, lo que dificulta la interpretaci贸n directa.\n",
    "- Significado: Penaliza m谩s los errores grandes que los peque帽os debido al cuadrado.\n",
    "- Ejemplo: Si el MSE es 250,000, significa que los errores al cuadrado suman a esta cantidad en promedio.\n",
    "- Ventaja: Penaliza grandes desviaciones, 煤til si el objetivo es evitar errores grandes.\n",
    "- Limitaci贸n: Dif铆cil de interpretar directamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El R虏 mide la proporci贸n de la varianza de la variable dependiente explicada por el modelo\n",
    "\n",
    "- Escala: Va de 0 a 1 (puede ser negativo si el modelo es peor que simplemente predecir la media).\n",
    "- Significado: Representa qu茅 porcentaje de la variabilidad de los datos es explicada por el modelo.\n",
    "- - R虏 cercano a 1: El modelo explica bien los datos.\n",
    "- - R虏 cercano a 0: El modelo no explica la variabilidad de los datos.\n",
    "- Ejemplo: Un 2=0.85 indica que el 85% de la variaci贸n en los precios de apartamentos es explicada por el modelo.\n",
    "- Ventaja: F谩cil de interpretar como un porcentaje.\n",
    "- Limitaci贸n: No considera el n煤mero de variables, lo que puede llevar a problemas de sobreajuste (usa R2 ajustado para corregir esto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores SHAP (SHapley Additive exPlanations) son una herramienta poderosa para interpretar modelos de machine learning. Se basan en la teor铆a de juegos y asignan a cada caracter铆stica un valor que representa su contribuci贸n al resultado del modelo.\n",
    "\n",
    "Interpretaci贸n de los Valores SHAP\n",
    "1. A Nivel Global (Modelo Completo)\n",
    "\n",
    "Importancia de las caracter铆sticas: SHAP puede mostrar las caracter铆sticas m谩s importantes al calcular el promedio absoluto de los valores SHAP para cada caracter铆stica.\n",
    "- Ejemplo: Si la caracter铆stica \"tama帽o\" tiene valores SHAP altos en magnitud, significa que el tama帽o tiene un gran impacto en las predicciones del modelo.\n",
    "\n",
    "Visualizaci贸n Global:\n",
    "\n",
    "- Summary Plot: Muestra las caracter铆sticas m谩s importantes y c贸mo afectan la predicci贸n.\n",
    "- Puntos rojos: Valores altos de la caracter铆stica.\n",
    "- Puntos azules: Valores bajos de la caracter铆stica.\n",
    "\n",
    "2. A Nivel Local (Predicci贸n Individual)\n",
    "\n",
    "Contribuci贸n de cada caracter铆stica: Los valores SHAP indican c贸mo cada caracter铆stica contribuy贸 a una predicci贸n espec铆fica.\n",
    "- Ejemplo: Para un apartamento espec铆fico, \"ubicaci贸n\" podr铆a agregar $20,000 a la predicci贸n, mientras que \"tama帽o\" podr铆a restar $5,000.\n",
    "\n",
    "Visualizaci贸n Local:\n",
    "\n",
    "- Force Plot: Representa gr谩ficamente c贸mo las caracter铆sticas mueven la predicci贸n desde el valor base hacia el valor final.\n",
    "\n",
    "3. Ejemplo de Resultados\n",
    "\n",
    "- Summary Plot (Importancia Global):\n",
    "\n",
    "Muestra las caracter铆sticas ordenadas por su importancia.\n",
    "Puntos dispersos indican c贸mo los valores altos o bajos de una caracter铆stica afectan las predicciones.\n",
    "\n",
    "- Force Plot (Predicci贸n Individual):\n",
    "\n",
    "Una barra horizontal con el valor base y flechas que representan las contribuciones de las caracter铆sticas.\n",
    "Las flechas hacia la derecha aumentan la predicci贸n; las flechas hacia la izquierda la disminuyen.\n",
    "\n",
    "- Dependence Plot (Interacciones):\n",
    "\n",
    "Un gr谩fico de dispersi贸n que muestra c贸mo una caracter铆stica afecta las predicciones y c贸mo interact煤a con otra caracter铆stica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelos de clasificaci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base de clasificaci贸n\n",
    "clf_model = RandomForestClassifier(random_state=42)\n",
    "clf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = clf_model.predict(X_test)\n",
    "\n",
    "# C谩lculo de m茅tricas\n",
    "precision = precision_score(y_true, y_pred)  \n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Evaluaci贸n\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Interpretabilidad\n",
    "feature_importances = clf_model.feature_importances_\n",
    "plt.barh(X.columns, feature_importances)\n",
    "plt.title(\"Importancia de Caracter铆sticas\")\n",
    "plt.show()\n",
    "\n",
    "# SHAP para explicabilidad\n",
    "explainer = shap.Explainer(clf_model, X_test)\n",
    "shap_values = explainer(X_test)\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C贸mo Interpretar las M茅tricas\n",
    "- Precisi贸n (Precision): \n",
    "\n",
    "Proporci贸n de verdaderos positivos entre todas las predicciones positivas\n",
    "Mide qu茅 tan confiable es una predicci贸n positiva.\n",
    "Ideal para minimizar falsos positivos.\n",
    "\n",
    "- Recall (Sensibilidad):\n",
    "\n",
    "Proporci贸n de verdaderos positivos entre todos los casos positivos reales\n",
    "Indica la capacidad del modelo para identificar positivos.\n",
    "Ideal para minimizar falsos negativos.\n",
    "\n",
    "- F1-Score:\n",
    "\n",
    "Promedio arm贸nico entre precisi贸n y recall\n",
    "til cuando existe un desequilibrio de clases, ya que balancea ambas m茅tricas.\n",
    "\n",
    "- Informe de Clasificaci贸n (Classification Report):\n",
    "\n",
    "Proporciona un resumen detallado de las m茅tricas por clase y globalmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante: precisi贸n (que proporci贸n de instancias identifiqu茅- verdaderas positivas) y recall (cuantas de las que ten铆a para identificar pude hacerlo correctamente)\n",
    "\n",
    "Dependiendo el tipo de problema quiero mayor precisi贸n o mayor recall. Ejemplo: C谩ncer de pulm贸n mayor precisi贸n ya que quiero que a las personas que les hago la imagen, la mayor铆a las identifique correctamente y detecci贸n de fraude bancario mayor recall ya que quiero identificar la mayor cantidad de verdaderos fraudes posibles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretabilidad\n",
    "\n",
    "1. C贸mo se explica la regresi贸n lineal\n",
    "\n",
    "La regresi贸n lineal es un modelo interpretable basado en una ecuaci贸n matem谩tica que describe la relaci贸n entre las variables independientes (X) y la variable dependiente (Y)\n",
    "\n",
    "Interpretaci贸n\n",
    "\n",
    "Cada coeficiente indica la magnitud y direcci贸n de la relaci贸n entre la variable independiente y la variable objetivo.\n",
    "- 金>0: Relaci贸n positiva.\n",
    "- 金<0: Relaci贸n negativa.\n",
    "\n",
    "La importancia de las variables puede deducirse directamente del tama帽o absoluto de los coeficientes (considerando que las variables est茅n estandarizadas).\n",
    "\n",
    "2. C贸mo identificar las variables m谩s y menos importantes\n",
    "\n",
    "Para Modelos Lineales\n",
    "\n",
    "- Tama帽o del Coeficiente (金): Si las variables est谩n estandarizadas, los coeficientes absolutos m谩s grandes indican mayor importancia.\n",
    "\n",
    "- Pruebas de Significancia (p-valores): Si un coeficiente tiene un p-valor alto (por ejemplo, > 0.05), puede no ser significativo para explicar \n",
    "\n",
    "Para Modelos No Lineales\n",
    "\n",
    "- Feature Importance:\n",
    "\n",
    "En modelos como Random Forest o Gradient Boosting, se utiliza la importancia de caracter铆sticas basada en la reducci贸n de error (como Gini o entrop铆a). Librer铆as como SHAP o LIME permiten medir el impacto de cada variable en la predicci贸n.\n",
    "\n",
    "Visualizaciones:\n",
    "\n",
    "- SHAP Summary Plot: Muestra qu茅 variables tienen mayor impacto global.\n",
    "- Dependence Plot: Muestra c贸mo una variable afecta las predicciones y si interact煤a con otras.\n",
    "\n",
    "3. Qu茅 es un Random Forest\n",
    "\n",
    "Un Random Forest es un modelo de machine learning basado en 谩rboles de decisi贸n que utiliza el m茅todo de ensamble. Es una colecci贸n de 谩rboles de decisi贸n entrenados en diferentes subconjuntos del dataset y caracter铆sticas.\n",
    "\n",
    "Caracter铆sticas Clave: Cada 谩rbol hace una predicci贸n y el bosque combina estas predicciones (votaci贸n en clasificaci贸n o promedio en regresi贸n).\n",
    "\n",
    "Usa t茅cnicas como:\n",
    "\n",
    "- Bagging: Selecci贸n aleatoria de muestras para entrenar cada 谩rbol.\n",
    "- Feature Sampling: Selecci贸n aleatoria de caracter铆sticas para dividir nodos.\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Robusto frente a overfitting.\n",
    "- Maneja datos con alta dimensionalidad.\n",
    "- Permite medir la importancia de las variables.\n",
    "\n",
    "4. Qu茅 resultados obtengo con un Random Forest\n",
    "\n",
    "Predicciones:\n",
    "\n",
    "- En problemas de clasificaci贸n, predice la clase con mayor votaci贸n.\n",
    "\n",
    "- En problemas de regresi贸n, predice el promedio de las salidas de los 谩rboles.\n",
    "\n",
    "Importancia de las Caracter铆sticas: Cuantifica qu茅 variables contribuyen m谩s a reducir el error.\n",
    "\n",
    "Desempe帽o del Modelo: M茅tricas como precisi贸n, recall, F1-score (clasificaci贸n) o R虏, MAE, MSE (regresi贸n).\n",
    "\n",
    "Interpretaci贸n Global: Importancia promedio de cada caracter铆stica.\n",
    "\n",
    "5. C贸mo interpreto el modelo a nivel global y a nivel de instancias\n",
    "\n",
    "A Nivel Global\n",
    "- Feature Importance: Muestra el impacto promedio de cada caracter铆stica en las predicciones.\n",
    "- Visualizaciones SHAP:\n",
    "- Distribuci贸n de Errores: Analiza si el modelo tiene un desempe帽o consistente en diferentes rangos del dataset.\n",
    "\n",
    "A Nivel de Instancias\n",
    "- SHAP Values:Muestra c贸mo cada caracter铆stica contribuye a una predicci贸n espec铆fica.\n",
    "- Force Plot: Representa gr谩ficamente c贸mo las caracter铆sticas mueven la predicci贸n desde el valor base.\n",
    "- LIME: Genera explicaciones localizadas mediante la perturbaci贸n de los datos de entrada.\n",
    "\n",
    "6. C贸mo explico una predicci贸n o grupo de predicciones\n",
    "\n",
    "Predicci贸n Individual\n",
    "- SHAP Force Plot:Muestra c贸mo las caracter铆sticas espec铆ficas influyen en la predicci贸n. Ejemplo: \"El tama帽o del apartamento agreg贸 $20,000 y la ubicaci贸n rest贸 $5,000 al precio final.\"\n",
    "- An谩lisis de Errores: Compara la predicci贸n con el valor real para detectar patrones o inconsistencias.\n",
    "\n",
    "Grupo de Predicciones\n",
    "- SHAP Summary Plot: Destaca patrones globales en la influencia de las caracter铆sticas.\n",
    "- Segmentaci贸n: Agrupa instancias con caracter铆sticas similares y analiza c贸mo el modelo predice en esos segmentos.\n",
    "\n",
    "Explicaciones para Negocio\n",
    "\n",
    "Presenta insights accionables, como:\n",
    "- \"El precio de venta de apartamentos est谩 fuertemente influenciado por la ubicaci贸n y el 谩rea.\"\n",
    "- \"Clientes en estratos altos tienden a obtener precios m谩s precisos.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparaci贸n de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: GridSearch para optimizar hiperpar谩metros\n",
    "param_grid = {'n_estimators': [100, 200], 'max_depth': [10, 20]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Validar si mejora es significativa\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix (Mejor Modelo):\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(\"ROC AUC (Mejor Modelo):\", roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Justicia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar justicia con variables sensibles\n",
    "sensitive_feature = 'gender'  # Ejemplo: columna sensible\n",
    "group_a = df[df[sensitive_feature] == 0]\n",
    "group_b = df[df[sensitive_feature] == 1]\n",
    "\n",
    "# Comparar m茅tricas entre grupos\n",
    "for group, data in {'Group A': group_a, 'Group B': group_b}.items():\n",
    "    y_true = data['target']\n",
    "    y_pred = clf_model.predict(data.drop('target', axis=1))\n",
    "    print(f\"{group} Metrics\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paridad estad铆stica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ejemplo de datos\n",
    "data = pd.DataFrame({\n",
    "    'gender': ['male', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male'],\n",
    "    'y_true': [1, 0, 1, 1, 0, 0, 1, 0, 0, 1],  # Etiquetas reales\n",
    "    'y_pred': [1, 0, 1, 1, 1, 0, 0, 1, 0, 1]   # Predicciones del modelo\n",
    "})\n",
    "\n",
    "# Funci贸n para calcular la tasa de predicci贸n positiva (paridad estad铆stica)\n",
    "def positive_rate(data, group_col, pred_col):\n",
    "    rates = data.groupby(group_col)[pred_col].mean()\n",
    "    return rates\n",
    "\n",
    "# C谩lculo de tasas de predicci贸n positiva\n",
    "positive_rates = positive_rate(data, group_col='gender', pred_col='y_pred')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Tasas de predicci贸n positiva por grupo:\")\n",
    "print(positive_rates)\n",
    "\n",
    "# Validaci贸n de paridad estad铆stica\n",
    "threshold = 0.1  # Diferencia m谩xima aceptable (ajustable seg煤n el caso)\n",
    "is_fair = np.abs(positive_rates.max() - positive_rates.min()) <= threshold\n",
    "\n",
    "if is_fair:\n",
    "    print(\"\\nEl modelo cumple con la paridad estad铆stica.\")\n",
    "else:\n",
    "    print(\"\\nEl modelo NO cumple con la paridad estad铆stica.\")\n",
    "    print(f\"Diferencia entre tasas: {positive_rates.max() - positive_rates.min():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paridad condicional estad铆stica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ejemplo de datos\n",
    "data = pd.DataFrame({\n",
    "    'gender': ['male', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male'],\n",
    "    'income_level': ['high', 'high', 'medium', 'low', 'low', 'medium', 'low', 'high', 'medium', 'high'],\n",
    "    'y_true': [1, 0, 1, 1, 0, 0, 1, 0, 0, 1],  # Etiquetas reales\n",
    "    'y_pred': [1, 0, 1, 1, 1, 0, 0, 1, 0, 1]   # Predicciones del modelo\n",
    "})\n",
    "\n",
    "# Funci贸n para calcular la tasa de predicci贸n positiva condicional\n",
    "def conditional_positive_rate(data, group_col, condition_col, pred_col):\n",
    "    \"\"\"\n",
    "    Calcula la tasa de predicci贸n positiva condicionada a una caracter铆stica.\n",
    "    \n",
    "    Args:\n",
    "    - data (DataFrame): Dataset que contiene los datos.\n",
    "    - group_col (str): Columna del atributo sensible (ej., g茅nero).\n",
    "    - condition_col (str): Columna del atributo condicional (ej., nivel de ingresos).\n",
    "    - pred_col (str): Columna de las predicciones (ej., y_pred).\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Tasa de predicci贸n positiva por grupo y condici贸n.\n",
    "    \"\"\"\n",
    "    rates = data.groupby([condition_col, group_col])[pred_col].mean().unstack()\n",
    "    return rates\n",
    "\n",
    "# C谩lculo de tasas de predicci贸n positiva condicional\n",
    "conditional_rates = conditional_positive_rate(data, group_col='gender', condition_col='income_level', pred_col='y_pred')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Tasas de predicci贸n positiva condicionadas:\")\n",
    "print(conditional_rates)\n",
    "\n",
    "# Validaci贸n de paridad condicional estad铆stica\n",
    "threshold = 0.1  # Diferencia m谩xima aceptable (ajustable seg煤n el caso)\n",
    "max_diff_by_condition = conditional_rates.max(axis=1) - conditional_rates.min(axis=1)\n",
    "is_fair = (max_diff_by_condition <= threshold).all()\n",
    "\n",
    "if is_fair:\n",
    "    print(\"\\nEl modelo cumple con la paridad condicional estad铆stica.\")\n",
    "else:\n",
    "    print(\"\\nEl modelo NO cumple con la paridad condicional estad铆stica.\")\n",
    "    print(f\"Diferencias m谩ximas por condici贸n:\\n{max_diff_by_condition}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paridad de Predicci贸n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ejemplo de datos\n",
    "data = pd.DataFrame({\n",
    "    'gender': ['male', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male'],\n",
    "    'y_true': [1, 0, 1, 1, 0, 0, 1, 0, 0, 1],  # Etiquetas reales\n",
    "    'y_pred': [1, 0, 1, 1, 1, 0, 0, 1, 0, 1]   # Predicciones del modelo\n",
    "})\n",
    "\n",
    "# Funci贸n para calcular la precisi贸n positiva por grupo (Predictive Parity)\n",
    "def positive_precision(data, group_col, true_col, pred_col):\n",
    "    \"\"\"\n",
    "    Calcula la precisi贸n positiva por grupo.\n",
    "    \n",
    "    Args:\n",
    "    - data (DataFrame): Dataset con los datos.\n",
    "    - group_col (str): Columna del atributo sensible (ej., g茅nero).\n",
    "    - true_col (str): Columna de las etiquetas reales (ej., y_true).\n",
    "    - pred_col (str): Columna de las predicciones del modelo (ej., y_pred).\n",
    "\n",
    "    Returns:\n",
    "    - Series: Precisi贸n positiva por grupo.\n",
    "    \"\"\"\n",
    "    group_data = data[data[pred_col] == 1]  # Filtrar solo predicciones positivas\n",
    "    precision = group_data.groupby(group_col).apply(\n",
    "        lambda x: np.mean(x[true_col])\n",
    "    )\n",
    "    return precision\n",
    "\n",
    "# Calcular la precisi贸n positiva por grupo\n",
    "positive_precisions = positive_precision(data, group_col='gender', true_col='y_true', pred_col='y_pred')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Precisi贸n positiva por grupo:\")\n",
    "print(positive_precisions)\n",
    "\n",
    "# Validaci贸n de paridad de predicci贸n\n",
    "threshold = 0.1  # Diferencia m谩xima aceptable (ajustable seg煤n el caso)\n",
    "is_fair = np.abs(positive_precisions.max() - positive_precisions.min()) <= threshold\n",
    "\n",
    "if is_fair:\n",
    "    print(\"\\nEl modelo cumple con la paridad de predicci贸n.\")\n",
    "else:\n",
    "    print(\"\\nEl modelo NO cumple con la paridad de predicci贸n.\")\n",
    "    print(f\"Diferencia entre precisiones: {positive_precisions.max() - positive_precisions.min():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Igualdad de precisi贸n total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ejemplo de datos\n",
    "data = pd.DataFrame({\n",
    "    'gender': ['male', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male'],\n",
    "    'y_true': [1, 0, 1, 1, 0, 0, 1, 0, 0, 1],  # Etiquetas reales\n",
    "    'y_pred': [1, 0, 1, 1, 1, 0, 0, 1, 0, 1]   # Predicciones del modelo\n",
    "})\n",
    "\n",
    "# Funci贸n para calcular la precisi贸n total por grupo\n",
    "def group_accuracy(data, group_col, true_col, pred_col):\n",
    "    \"\"\"\n",
    "    Calcula la precisi贸n total por grupo.\n",
    "    \n",
    "    Args:\n",
    "    - data (DataFrame): Dataset con los datos.\n",
    "    - group_col (str): Columna del atributo sensible (ej., g茅nero).\n",
    "    - true_col (str): Columna de las etiquetas reales (ej., y_true).\n",
    "    - pred_col (str): Columna de las predicciones del modelo (ej., y_pred).\n",
    "\n",
    "    Returns:\n",
    "    - Series: Precisi贸n total por grupo.\n",
    "    \"\"\"\n",
    "    accuracy = data.groupby(group_col).apply(\n",
    "        lambda x: np.mean(x[true_col] == x[pred_col])\n",
    "    )\n",
    "    return accuracy\n",
    "\n",
    "# Calcular la precisi贸n total por grupo\n",
    "accuracy_by_group = group_accuracy(data, group_col='gender', true_col='y_true', pred_col='y_pred')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Precisi贸n total por grupo:\")\n",
    "print(accuracy_by_group)\n",
    "\n",
    "# Validaci贸n de igualdad de precisi贸n total\n",
    "threshold = 0.1  # Diferencia m谩xima aceptable (ajustable seg煤n el caso)\n",
    "is_fair = np.abs(accuracy_by_group.max() - accuracy_by_group.min()) <= threshold\n",
    "\n",
    "if is_fair:\n",
    "    print(\"\\nEl modelo cumple con la igualdad de precisi贸n total.\")\n",
    "else:\n",
    "    print(\"\\nEl modelo NO cumple con la igualdad de precisi贸n total.\")\n",
    "    print(f\"Diferencia entre precisiones: {accuracy_by_group.max() - accuracy_by_group.min():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Buena calibraci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# Ejemplo de datos\n",
    "data = pd.DataFrame({\n",
    "    'gender': ['male', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male'],\n",
    "    'y_true': [1, 0, 1, 1, 0, 0, 1, 0, 0, 1],  # Etiquetas reales\n",
    "    'y_prob': [0.9, 0.1, 0.8, 0.7, 0.4, 0.3, 0.6, 0.2, 0.5, 0.9]  # Probabilidades predichas\n",
    "})\n",
    "\n",
    "# Funci贸n para calcular el Brier Score por grupo\n",
    "def brier_score_by_group(data, group_col, true_col, prob_col):\n",
    "    \"\"\"\n",
    "    Calcula el Brier Score por grupo.\n",
    "\n",
    "    Args:\n",
    "    - data (DataFrame): Dataset con los datos.\n",
    "    - group_col (str): Columna del atributo sensible (ej., g茅nero).\n",
    "    - true_col (str): Columna de las etiquetas reales (ej., y_true).\n",
    "    - prob_col (str): Columna de las probabilidades predichas (ej., y_prob).\n",
    "\n",
    "    Returns:\n",
    "    - Series: Brier Score por grupo.\n",
    "    \"\"\"\n",
    "    return data.groupby(group_col).apply(\n",
    "        lambda x: brier_score_loss(x[true_col], x[prob_col])\n",
    "    )\n",
    "\n",
    "# Calcular el Brier Score por grupo\n",
    "brier_scores = brier_score_by_group(data, group_col='gender', true_col='y_true', prob_col='y_prob')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Brier Score por grupo:\")\n",
    "print(brier_scores)\n",
    "\n",
    "# Validaci贸n de buena calibraci贸n\n",
    "threshold = 0.05  # Diferencia m谩xima aceptable (ajustable seg煤n el contexto)\n",
    "is_fair = np.abs(brier_scores.max() - brier_scores.min()) <= threshold\n",
    "\n",
    "if is_fair:\n",
    "    print(\"\\nEl modelo cumple con buena calibraci贸n.\")\n",
    "else:\n",
    "    print(\"\\nEl modelo NO cumple con buena calibraci贸n.\")\n",
    "    print(f\"Diferencia entre Brier Scores: {brier_scores.max() - brier_scores.min():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discriminaci贸n causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from econml.dml import CausalForestDML\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ejemplo de datos\n",
    "data = pd.DataFrame({\n",
    "    'gender': ['male', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male'],\n",
    "    'age': [25, 30, 45, 35, 50, 40, 28, 60, 22, 27],  # Edad como variable no sensible\n",
    "    'education': [1, 2, 3, 2, 1, 1, 3, 2, 2, 3],  # Nivel educativo\n",
    "    'y_true': [1, 0, 1, 1, 0, 0, 1, 0, 0, 1],  # Etiquetas reales\n",
    "    'y_pred': [0.9, 0.1, 0.8, 0.7, 0.4, 0.3, 0.6, 0.2, 0.5, 0.9]  # Probabilidades predichas\n",
    "})\n",
    "\n",
    "# Separar las variables predictoras y la variable sensible\n",
    "X = data[['age', 'education']]  # Variables no sensibles\n",
    "T = data['gender']  # Atributo sensible (gender)\n",
    "y = data['y_true']  # Etiqueta\n",
    "\n",
    "# Entrenar un modelo con y_pred como la predicci贸n\n",
    "model = LogisticRegression()\n",
    "X_train, X_test, y_train, y_test, T_train, T_test = train_test_split(X, y, T, test_size=0.3, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precisi贸n del modelo sin considerar el atributo sensible: {accuracy:.2f}\")\n",
    "\n",
    "# Usamos CausalForestDML para analizar la causalidad y la discriminaci贸n\n",
    "cf = CausalForestDML(model_y=LogisticRegression(), model_t=LogisticRegression(), discrete_treatment=True)\n",
    "\n",
    "cf.fit(X_train, y_train, T_train)\n",
    "\n",
    "# An谩lisis de la discriminaci贸n causal - Predicci贸n ajustada sin el atributo sensible\n",
    "y_pred_adjusted = cf.predict(X_test)\n",
    "\n",
    "# Comparaci贸n de las predicciones ajustadas con las originales\n",
    "print(f\"Precisi贸n del modelo con ajuste causal: {accuracy_score(y_test, y_pred_adjusted):.2f}\")\n",
    "\n",
    "# Si la diferencia es significativa, hay discriminaci贸n causal\n",
    "discriminacion_causal = np.abs(accuracy - accuracy_score(y_test, y_pred_adjusted))\n",
    "\n",
    "threshold = 0.05  # Ajusta este umbral seg煤n el contexto\n",
    "if discriminacion_causal > threshold:\n",
    "    print(\"\\nEl modelo muestra discriminaci贸n causal.\")\n",
    "else:\n",
    "    print(\"\\nEl modelo no muestra discriminaci贸n causal.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Despliegue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo para despliegue\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "\n",
    "# Cargar y predecir con modelo desplegado\n",
    "model = joblib.load('best_model.pkl')\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pruebas A/B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "\n",
    "# Paso 1: Entrenar dos modelos\n",
    "# Modelo A (Base)\n",
    "model_a = RandomForestClassifier(random_state=42)\n",
    "model_a.fit(X_train, y_train)\n",
    "y_pred_a = model_a.predict(X_test)\n",
    "\n",
    "# Modelo B (Mejorado)\n",
    "model_b = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_b.fit(X_train, y_train)\n",
    "y_pred_b = model_b.predict(X_test)\n",
    "\n",
    "# Paso 2: Evaluar los modelos\n",
    "# (Cambia a las m茅tricas correspondientes si es un problema de regresi贸n)\n",
    "accuracy_a = accuracy_score(y_test, y_pred_a)\n",
    "accuracy_b = accuracy_score(y_test, y_pred_b)\n",
    "\n",
    "print(f\"Accuracy Modelo A: {accuracy_a}\")\n",
    "print(f\"Accuracy Modelo B: {accuracy_b}\")\n",
    "\n",
    "# Paso 3: Comparar predicciones (Prueba A/B)\n",
    "# M茅trica para cada ejemplo individual\n",
    "errors_a = y_test != y_pred_a\n",
    "errors_b = y_test != y_pred_b\n",
    "\n",
    "# T-Test pareado (diferencias medias)\n",
    "t_stat, p_value = ttest_rel(errors_a, errors_b)\n",
    "print(f\"T-Test: t-statistic = {t_stat}, p-value = {p_value}\")\n",
    "\n",
    "# Prueba de Wilcoxon (no param茅trica)\n",
    "wilcoxon_stat, wilcoxon_p = wilcoxon(errors_a, errors_b)\n",
    "print(f\"Wilcoxon: stat = {wilcoxon_stat}, p-value = {wilcoxon_p}\")\n",
    "\n",
    "# Interpretaci贸n de resultados\n",
    "if p_value < 0.05:\n",
    "    print(\"La diferencia entre los modelos es estad铆sticamente significativa (T-Test).\")\n",
    "else:\n",
    "    print(\"No hay evidencia suficiente para afirmar que los modelos son diferentes (T-Test).\")\n",
    "\n",
    "if wilcoxon_p < 0.05:\n",
    "    print(\"La diferencia entre los modelos es estad铆sticamente significativa (Wilcoxon).\")\n",
    "else:\n",
    "    print(\"No hay evidencia suficiente para afirmar que los modelos son diferentes (Wilcoxon).\")\n",
    "\n",
    "# Paso 4: Visualizar diferencias en desempe帽o\n",
    "# Porcentaje de aciertos por modelo\n",
    "errors_a_mean = np.mean(errors_a)\n",
    "errors_b_mean = np.mean(errors_b)\n",
    "\n",
    "plt.bar(['Modelo A', 'Modelo B'], [1-errors_a_mean, 1-errors_b_mean])\n",
    "plt.ylabel('Proporci贸n de aciertos')\n",
    "plt.title('Comparaci贸n entre modelos')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular errores absolutos en regresi贸n\n",
    "errors_a = np.abs(y_test - model_a.predict(X_test))\n",
    "errors_b = np.abs(y_test - model_b.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supuestos de negocio\n",
    "income_per_correct_prediction = 100  # Ingreso por predicci贸n correcta\n",
    "cost_per_error = 50  # Costo por predicci贸n incorrecta\n",
    "model_cost = 10000  # Costo de desarrollo e implementaci贸n\n",
    "\n",
    "# Ingresos y costos del Modelo A\n",
    "correct_a = sum(y_test == y_pred_a)\n",
    "incorrect_a = sum(y_test != y_pred_a)\n",
    "income_a = correct_a * income_per_correct_prediction\n",
    "cost_a = incorrect_a * cost_per_error + model_cost\n",
    "roi_a = (income_a - cost_a) / model_cost\n",
    "\n",
    "# Ingresos y costos del Modelo B\n",
    "correct_b = sum(y_test == y_pred_b)\n",
    "incorrect_b = sum(y_test != y_pred_b)\n",
    "income_b = correct_b * income_per_correct_prediction\n",
    "cost_b = incorrect_b * cost_per_error + model_cost\n",
    "roi_b = (income_b - cost_b) / model_cost\n",
    "\n",
    "# Punto de Equilibrio para el Modelo Mejorado\n",
    "break_even_correct_predictions = model_cost / income_per_correct_prediction\n",
    "\n",
    "# Resultados\n",
    "print(f\"Modelo A - Ingreso: ${income_a}, Costo: ${cost_a}, ROI: {roi_a:.2f}\")\n",
    "print(f\"Modelo B - Ingreso: ${income_b}, Costo: ${cost_b}, ROI: {roi_b:.2f}\")\n",
    "print(f\"Punto de Equilibrio (Modelo Mejorado): {break_even_correct_predictions:.0f} predicciones correctas\")\n",
    "\n",
    "# Comparaci贸n Visual\n",
    "models = ['Modelo A', 'Modelo B']\n",
    "rois = [roi_a, roi_b]\n",
    "\n",
    "plt.bar(models, rois)\n",
    "plt.ylabel('ROI')\n",
    "plt.title('Comparaci贸n de ROI entre Modelos')\n",
    "plt.axhline(0, color='red', linestyle='--', label='Punto de Equilibrio')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

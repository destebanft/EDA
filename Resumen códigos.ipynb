{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repaso parcial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn\n",
    "%pip install seaborn\n",
    "%pip install --upgrade scikit-learn imbalanced-learn\n",
    "%pip install statsmodels\n",
    "%pip install mlxtend\n",
    "%pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías básicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, confusion_matrix, classification_report, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "# Justicia\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap  # Para interpretabilidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar y procesar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar con los datos que te proporcionen\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Dividir en características (X) y etiqueta (y)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# División de los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar si es necesario\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelos de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base de regresión\n",
    "reg_model = RandomForestRegressor(random_state=42)\n",
    "reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = reg_model.predict(X_test)\n",
    "\n",
    "# Evaluación\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# Interpretabilidad\n",
    "feature_importances = reg_model.feature_importances_\n",
    "plt.barh(X.columns, feature_importances)\n",
    "plt.title(\"Importancia de Características\")\n",
    "plt.show()\n",
    "\n",
    "# SHAP para explicabilidad\n",
    "explainer = shap.Explainer(reg_model, X_test)\n",
    "shap_values = explainer(X_test)\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "\n",
    "# Visualización Local: Predicción individual\n",
    "shap.force_plot(explainer.expected_value, shap_values[0].values, X[0])\n",
    "\n",
    "# Visualización de Dependencia\n",
    "shap.dependence_plot(\"RM\", shap_values.values, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Mean Absolute Error (MAE) mide el promedio de los errores absolutos entre las predicciones del modelo y los valores reales. \n",
    "\n",
    "- Escala: Está en las mismas unidades que la variable objetivo.\n",
    "- Significado: Muestra el error promedio que comete el modelo al hacer predicciones.\n",
    "- Ejemplo: Si el MAE es 500 y la variable objetivo representa el precio de apartamentos en dólares, significa que, en promedio, el modelo se equivoca por $500 en cada predicción.\n",
    "- Ventaja: Fácil de interpretar.\n",
    "- Limitación: No penaliza grandes errores más que pequeños, ya que toma valores absolutos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Mean Squared Error (MSE) mide el promedio de los errores elevados al cuadrado\n",
    "\n",
    "- Escala: Está en las unidades cuadradas de la variable objetivo, lo que dificulta la interpretación directa.\n",
    "- Significado: Penaliza más los errores grandes que los pequeños debido al cuadrado.\n",
    "- Ejemplo: Si el MSE es 250,000, significa que los errores al cuadrado suman a esta cantidad en promedio.\n",
    "- Ventaja: Penaliza grandes desviaciones, útil si el objetivo es evitar errores grandes.\n",
    "- Limitación: Difícil de interpretar directamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El R² mide la proporción de la varianza de la variable dependiente explicada por el modelo\n",
    "\n",
    "- Escala: Va de 0 a 1 (puede ser negativo si el modelo es peor que simplemente predecir la media).\n",
    "- Significado: Representa qué porcentaje de la variabilidad de los datos es explicada por el modelo.\n",
    "- - R² cercano a 1: El modelo explica bien los datos.\n",
    "- - R² cercano a 0: El modelo no explica la variabilidad de los datos.\n",
    "- Ejemplo: Un 𝑅2=0.85 indica que el 85% de la variación en los precios de apartamentos es explicada por el modelo.\n",
    "- Ventaja: Fácil de interpretar como un porcentaje.\n",
    "- Limitación: No considera el número de variables, lo que puede llevar a problemas de sobreajuste (usa R2 ajustado para corregir esto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores SHAP (SHapley Additive exPlanations) son una herramienta poderosa para interpretar modelos de machine learning. Se basan en la teoría de juegos y asignan a cada característica un valor que representa su contribución al resultado del modelo.\n",
    "\n",
    "Interpretación de los Valores SHAP\n",
    "1. A Nivel Global (Modelo Completo)\n",
    "\n",
    "Importancia de las características: SHAP puede mostrar las características más importantes al calcular el promedio absoluto de los valores SHAP para cada característica.\n",
    "- Ejemplo: Si la característica \"tamaño\" tiene valores SHAP altos en magnitud, significa que el tamaño tiene un gran impacto en las predicciones del modelo.\n",
    "\n",
    "Visualización Global:\n",
    "\n",
    "- Summary Plot: Muestra las características más importantes y cómo afectan la predicción.\n",
    "- Puntos rojos: Valores altos de la característica.\n",
    "- Puntos azules: Valores bajos de la característica.\n",
    "\n",
    "2. A Nivel Local (Predicción Individual)\n",
    "\n",
    "Contribución de cada característica: Los valores SHAP indican cómo cada característica contribuyó a una predicción específica.\n",
    "- Ejemplo: Para un apartamento específico, \"ubicación\" podría agregar $20,000 a la predicción, mientras que \"tamaño\" podría restar $5,000.\n",
    "\n",
    "Visualización Local:\n",
    "\n",
    "- Force Plot: Representa gráficamente cómo las características mueven la predicción desde el valor base hacia el valor final.\n",
    "\n",
    "3. Ejemplo de Resultados\n",
    "\n",
    "- Summary Plot (Importancia Global):\n",
    "\n",
    "Muestra las características ordenadas por su importancia.\n",
    "Puntos dispersos indican cómo los valores altos o bajos de una característica afectan las predicciones.\n",
    "\n",
    "- Force Plot (Predicción Individual):\n",
    "\n",
    "Una barra horizontal con el valor base y flechas que representan las contribuciones de las características.\n",
    "Las flechas hacia la derecha aumentan la predicción; las flechas hacia la izquierda la disminuyen.\n",
    "\n",
    "- Dependence Plot (Interacciones):\n",
    "\n",
    "Un gráfico de dispersión que muestra cómo una característica afecta las predicciones y cómo interactúa con otra característica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelos de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base de clasificación\n",
    "clf_model = RandomForestClassifier(random_state=42)\n",
    "clf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = clf_model.predict(X_test)\n",
    "\n",
    "# Cálculo de métricas\n",
    "precision = precision_score(y_true, y_pred)  \n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Evaluación\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Interpretabilidad\n",
    "feature_importances = clf_model.feature_importances_\n",
    "plt.barh(X.columns, feature_importances)\n",
    "plt.title(\"Importancia de Características\")\n",
    "plt.show()\n",
    "\n",
    "# SHAP para explicabilidad\n",
    "explainer = shap.Explainer(clf_model, X_test)\n",
    "shap_values = explainer(X_test)\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo Interpretar las Métricas\n",
    "- Precisión (Precision): \n",
    "\n",
    "Proporción de verdaderos positivos entre todas las predicciones positivas\n",
    "Mide qué tan confiable es una predicción positiva.\n",
    "Ideal para minimizar falsos positivos.\n",
    "\n",
    "- Recall (Sensibilidad):\n",
    "\n",
    "Proporción de verdaderos positivos entre todos los casos positivos reales\n",
    "Indica la capacidad del modelo para identificar positivos.\n",
    "Ideal para minimizar falsos negativos.\n",
    "\n",
    "- F1-Score:\n",
    "\n",
    "Promedio armónico entre precisión y recall\n",
    "Útil cuando existe un desequilibrio de clases, ya que balancea ambas métricas.\n",
    "\n",
    "- Informe de Clasificación (Classification Report):\n",
    "\n",
    "Proporciona un resumen detallado de las métricas por clase y globalmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante: precisión (que proporción de instancias identifiqué- verdaderas positivas) y recall (cuantas de las que tenía para identificar pude hacerlo correctamente)\n",
    "\n",
    "Dependiendo el tipo de problema quiero mayor precisión o mayor recall. Ejemplo: Cáncer de pulmón mayor precisión ya que quiero que a las personas que les hago la imagen, la mayoría las identifique correctamente y detección de fraude bancario mayor recall ya que quiero identificar la mayor cantidad de verdaderos fraudes posibles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretabilidad\n",
    "\n",
    "1. Cómo se explica la regresión lineal\n",
    "\n",
    "La regresión lineal es un modelo interpretable basado en una ecuación matemática que describe la relación entre las variables independientes (X) y la variable dependiente (Y)\n",
    "\n",
    "Interpretación\n",
    "\n",
    "Cada coeficiente indica la magnitud y dirección de la relación entre la variable independiente y la variable objetivo.\n",
    "- 𝛽𝑖>0: Relación positiva.\n",
    "- 𝛽𝑖<0: Relación negativa.\n",
    "\n",
    "La importancia de las variables puede deducirse directamente del tamaño absoluto de los coeficientes (considerando que las variables estén estandarizadas).\n",
    "\n",
    "2. Cómo identificar las variables más y menos importantes\n",
    "\n",
    "Para Modelos Lineales\n",
    "\n",
    "- Tamaño del Coeficiente (𝛽𝑖): Si las variables están estandarizadas, los coeficientes absolutos más grandes indican mayor importancia.\n",
    "\n",
    "- Pruebas de Significancia (p-valores): Si un coeficiente tiene un p-valor alto (por ejemplo, > 0.05), puede no ser significativo para explicar 𝑌\n",
    "\n",
    "Para Modelos No Lineales\n",
    "\n",
    "- Feature Importance:\n",
    "\n",
    "En modelos como Random Forest o Gradient Boosting, se utiliza la importancia de características basada en la reducción de error (como Gini o entropía). Librerías como SHAP o LIME permiten medir el impacto de cada variable en la predicción.\n",
    "\n",
    "Visualizaciones:\n",
    "\n",
    "- SHAP Summary Plot: Muestra qué variables tienen mayor impacto global.\n",
    "- Dependence Plot: Muestra cómo una variable afecta las predicciones y si interactúa con otras.\n",
    "\n",
    "3. Qué es un Random Forest\n",
    "\n",
    "Un Random Forest es un modelo de machine learning basado en árboles de decisión que utiliza el método de ensamble. Es una colección de árboles de decisión entrenados en diferentes subconjuntos del dataset y características.\n",
    "\n",
    "Características Clave: Cada árbol hace una predicción y el bosque combina estas predicciones (votación en clasificación o promedio en regresión).\n",
    "\n",
    "Usa técnicas como:\n",
    "\n",
    "- Bagging: Selección aleatoria de muestras para entrenar cada árbol.\n",
    "- Feature Sampling: Selección aleatoria de características para dividir nodos.\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Robusto frente a overfitting.\n",
    "- Maneja datos con alta dimensionalidad.\n",
    "- Permite medir la importancia de las variables.\n",
    "\n",
    "4. Qué resultados obtengo con un Random Forest\n",
    "\n",
    "Predicciones:\n",
    "\n",
    "- En problemas de clasificación, predice la clase con mayor votación.\n",
    "\n",
    "- En problemas de regresión, predice el promedio de las salidas de los árboles.\n",
    "\n",
    "Importancia de las Características: Cuantifica qué variables contribuyen más a reducir el error.\n",
    "\n",
    "Desempeño del Modelo: Métricas como precisión, recall, F1-score (clasificación) o R², MAE, MSE (regresión).\n",
    "\n",
    "Interpretación Global: Importancia promedio de cada característica.\n",
    "\n",
    "5. Cómo interpreto el modelo a nivel global y a nivel de instancias\n",
    "\n",
    "A Nivel Global\n",
    "- Feature Importance: Muestra el impacto promedio de cada característica en las predicciones.\n",
    "- Visualizaciones SHAP:\n",
    "- Distribución de Errores: Analiza si el modelo tiene un desempeño consistente en diferentes rangos del dataset.\n",
    "\n",
    "A Nivel de Instancias\n",
    "- SHAP Values:Muestra cómo cada característica contribuye a una predicción específica.\n",
    "- Force Plot: Representa gráficamente cómo las características mueven la predicción desde el valor base.\n",
    "- LIME: Genera explicaciones localizadas mediante la perturbación de los datos de entrada.\n",
    "\n",
    "6. Cómo explico una predicción o grupo de predicciones\n",
    "\n",
    "Predicción Individual\n",
    "- SHAP Force Plot:Muestra cómo las características específicas influyen en la predicción. Ejemplo: \"El tamaño del apartamento agregó $20,000 y la ubicación restó $5,000 al precio final.\"\n",
    "- Análisis de Errores: Compara la predicción con el valor real para detectar patrones o inconsistencias.\n",
    "\n",
    "Grupo de Predicciones\n",
    "- SHAP Summary Plot: Destaca patrones globales en la influencia de las características.\n",
    "- Segmentación: Agrupa instancias con características similares y analiza cómo el modelo predice en esos segmentos.\n",
    "\n",
    "Explicaciones para Negocio\n",
    "\n",
    "Presenta insights accionables, como:\n",
    "- \"El precio de venta de apartamentos está fuertemente influenciado por la ubicación y el área.\"\n",
    "- \"Clientes en estratos altos tienden a obtener precios más precisos.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: GridSearch para optimizar hiperparámetros\n",
    "param_grid = {'n_estimators': [100, 200], 'max_depth': [10, 20]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Validar si mejora es significativa\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix (Mejor Modelo):\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(\"ROC AUC (Mejor Modelo):\", roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Justicia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar justicia con variables sensibles\n",
    "sensitive_feature = 'gender'  # Ejemplo: columna sensible\n",
    "group_a = df[df[sensitive_feature] == 0]\n",
    "group_b = df[df[sensitive_feature] == 1]\n",
    "\n",
    "# Comparar métricas entre grupos\n",
    "for group, data in {'Group A': group_a, 'Group B': group_b}.items():\n",
    "    y_true = data['target']\n",
    "    y_pred = clf_model.predict(data.drop('target', axis=1))\n",
    "    print(f\"{group} Metrics\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paridad estadística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ejemplo de datos\n",
    "data = pd.DataFrame({\n",
    "    'gender': ['male', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male'],\n",
    "    'y_true': [1, 0, 1, 1, 0, 0, 1, 0, 0, 1],  # Etiquetas reales\n",
    "    'y_pred': [1, 0, 1, 1, 1, 0, 0, 1, 0, 1]   # Predicciones del modelo\n",
    "})\n",
    "\n",
    "# Función para calcular la tasa de predicción positiva (paridad estadística)\n",
    "def positive_rate(data, group_col, pred_col):\n",
    "    rates = data.groupby(group_col)[pred_col].mean()\n",
    "    return rates\n",
    "\n",
    "# Cálculo de tasas de predicción positiva\n",
    "positive_rates = positive_rate(data, group_col='gender', pred_col='y_pred')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Tasas de predicción positiva por grupo:\")\n",
    "print(positive_rates)\n",
    "\n",
    "# Validación de paridad estadística\n",
    "threshold = 0.1  # Diferencia máxima aceptable (ajustable según el caso)\n",
    "is_fair = np.abs(positive_rates.max() - positive_rates.min()) <= threshold\n",
    "\n",
    "if is_fair:\n",
    "    print(\"\\nEl modelo cumple con la paridad estadística.\")\n",
    "else:\n",
    "    print(\"\\nEl modelo NO cumple con la paridad estadística.\")\n",
    "    print(f\"Diferencia entre tasas: {positive_rates.max() - positive_rates.min():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paridad condicional estadística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ejemplo de datos\n",
    "data = pd.DataFrame({\n",
    "    'gender': ['male', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male'],\n",
    "    'income_level': ['high', 'high', 'medium', 'low', 'low', 'medium', 'low', 'high', 'medium', 'high'],\n",
    "    'y_true': [1, 0, 1, 1, 0, 0, 1, 0, 0, 1],  # Etiquetas reales\n",
    "    'y_pred': [1, 0, 1, 1, 1, 0, 0, 1, 0, 1]   # Predicciones del modelo\n",
    "})\n",
    "\n",
    "# Función para calcular la tasa de predicción positiva condicional\n",
    "def conditional_positive_rate(data, group_col, condition_col, pred_col):\n",
    "    \"\"\"\n",
    "    Calcula la tasa de predicción positiva condicionada a una característica.\n",
    "    \n",
    "    Args:\n",
    "    - data (DataFrame): Dataset que contiene los datos.\n",
    "    - group_col (str): Columna del atributo sensible (ej., género).\n",
    "    - condition_col (str): Columna del atributo condicional (ej., nivel de ingresos).\n",
    "    - pred_col (str): Columna de las predicciones (ej., y_pred).\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Tasa de predicción positiva por grupo y condición.\n",
    "    \"\"\"\n",
    "    rates = data.groupby([condition_col, group_col])[pred_col].mean().unstack()\n",
    "    return rates\n",
    "\n",
    "# Cálculo de tasas de predicción positiva condicional\n",
    "conditional_rates = conditional_positive_rate(data, group_col='gender', condition_col='income_level', pred_col='y_pred')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Tasas de predicción positiva condicionadas:\")\n",
    "print(conditional_rates)\n",
    "\n",
    "# Validación de paridad condicional estadística\n",
    "threshold = 0.1  # Diferencia máxima aceptable (ajustable según el caso)\n",
    "max_diff_by_condition = conditional_rates.max(axis=1) - conditional_rates.min(axis=1)\n",
    "is_fair = (max_diff_by_condition <= threshold).all()\n",
    "\n",
    "if is_fair:\n",
    "    print(\"\\nEl modelo cumple con la paridad condicional estadística.\")\n",
    "else:\n",
    "    print(\"\\nEl modelo NO cumple con la paridad condicional estadística.\")\n",
    "    print(f\"Diferencias máximas por condición:\\n{max_diff_by_condition}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paridad de Predicción "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ejemplo de datos\n",
    "data = pd.DataFrame({\n",
    "    'gender': ['male', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male'],\n",
    "    'y_true': [1, 0, 1, 1, 0, 0, 1, 0, 0, 1],  # Etiquetas reales\n",
    "    'y_pred': [1, 0, 1, 1, 1, 0, 0, 1, 0, 1]   # Predicciones del modelo\n",
    "})\n",
    "\n",
    "# Función para calcular la precisión positiva por grupo (Predictive Parity)\n",
    "def positive_precision(data, group_col, true_col, pred_col):\n",
    "    \"\"\"\n",
    "    Calcula la precisión positiva por grupo.\n",
    "    \n",
    "    Args:\n",
    "    - data (DataFrame): Dataset con los datos.\n",
    "    - group_col (str): Columna del atributo sensible (ej., género).\n",
    "    - true_col (str): Columna de las etiquetas reales (ej., y_true).\n",
    "    - pred_col (str): Columna de las predicciones del modelo (ej., y_pred).\n",
    "\n",
    "    Returns:\n",
    "    - Series: Precisión positiva por grupo.\n",
    "    \"\"\"\n",
    "    group_data = data[data[pred_col] == 1]  # Filtrar solo predicciones positivas\n",
    "    precision = group_data.groupby(group_col).apply(\n",
    "        lambda x: np.mean(x[true_col])\n",
    "    )\n",
    "    return precision\n",
    "\n",
    "# Calcular la precisión positiva por grupo\n",
    "positive_precisions = positive_precision(data, group_col='gender', true_col='y_true', pred_col='y_pred')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Precisión positiva por grupo:\")\n",
    "print(positive_precisions)\n",
    "\n",
    "# Validación de paridad de predicción\n",
    "threshold = 0.1  # Diferencia máxima aceptable (ajustable según el caso)\n",
    "is_fair = np.abs(positive_precisions.max() - positive_precisions.min()) <= threshold\n",
    "\n",
    "if is_fair:\n",
    "    print(\"\\nEl modelo cumple con la paridad de predicción.\")\n",
    "else:\n",
    "    print(\"\\nEl modelo NO cumple con la paridad de predicción.\")\n",
    "    print(f\"Diferencia entre precisiones: {positive_precisions.max() - positive_precisions.min():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Igualdad de precisión total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ejemplo de datos\n",
    "data = pd.DataFrame({\n",
    "    'gender': ['male', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male'],\n",
    "    'y_true': [1, 0, 1, 1, 0, 0, 1, 0, 0, 1],  # Etiquetas reales\n",
    "    'y_pred': [1, 0, 1, 1, 1, 0, 0, 1, 0, 1]   # Predicciones del modelo\n",
    "})\n",
    "\n",
    "# Función para calcular la precisión total por grupo\n",
    "def group_accuracy(data, group_col, true_col, pred_col):\n",
    "    \"\"\"\n",
    "    Calcula la precisión total por grupo.\n",
    "    \n",
    "    Args:\n",
    "    - data (DataFrame): Dataset con los datos.\n",
    "    - group_col (str): Columna del atributo sensible (ej., género).\n",
    "    - true_col (str): Columna de las etiquetas reales (ej., y_true).\n",
    "    - pred_col (str): Columna de las predicciones del modelo (ej., y_pred).\n",
    "\n",
    "    Returns:\n",
    "    - Series: Precisión total por grupo.\n",
    "    \"\"\"\n",
    "    accuracy = data.groupby(group_col).apply(\n",
    "        lambda x: np.mean(x[true_col] == x[pred_col])\n",
    "    )\n",
    "    return accuracy\n",
    "\n",
    "# Calcular la precisión total por grupo\n",
    "accuracy_by_group = group_accuracy(data, group_col='gender', true_col='y_true', pred_col='y_pred')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Precisión total por grupo:\")\n",
    "print(accuracy_by_group)\n",
    "\n",
    "# Validación de igualdad de precisión total\n",
    "threshold = 0.1  # Diferencia máxima aceptable (ajustable según el caso)\n",
    "is_fair = np.abs(accuracy_by_group.max() - accuracy_by_group.min()) <= threshold\n",
    "\n",
    "if is_fair:\n",
    "    print(\"\\nEl modelo cumple con la igualdad de precisión total.\")\n",
    "else:\n",
    "    print(\"\\nEl modelo NO cumple con la igualdad de precisión total.\")\n",
    "    print(f\"Diferencia entre precisiones: {accuracy_by_group.max() - accuracy_by_group.min():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Buena calibración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# Ejemplo de datos\n",
    "data = pd.DataFrame({\n",
    "    'gender': ['male', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male'],\n",
    "    'y_true': [1, 0, 1, 1, 0, 0, 1, 0, 0, 1],  # Etiquetas reales\n",
    "    'y_prob': [0.9, 0.1, 0.8, 0.7, 0.4, 0.3, 0.6, 0.2, 0.5, 0.9]  # Probabilidades predichas\n",
    "})\n",
    "\n",
    "# Función para calcular el Brier Score por grupo\n",
    "def brier_score_by_group(data, group_col, true_col, prob_col):\n",
    "    \"\"\"\n",
    "    Calcula el Brier Score por grupo.\n",
    "\n",
    "    Args:\n",
    "    - data (DataFrame): Dataset con los datos.\n",
    "    - group_col (str): Columna del atributo sensible (ej., género).\n",
    "    - true_col (str): Columna de las etiquetas reales (ej., y_true).\n",
    "    - prob_col (str): Columna de las probabilidades predichas (ej., y_prob).\n",
    "\n",
    "    Returns:\n",
    "    - Series: Brier Score por grupo.\n",
    "    \"\"\"\n",
    "    return data.groupby(group_col).apply(\n",
    "        lambda x: brier_score_loss(x[true_col], x[prob_col])\n",
    "    )\n",
    "\n",
    "# Calcular el Brier Score por grupo\n",
    "brier_scores = brier_score_by_group(data, group_col='gender', true_col='y_true', prob_col='y_prob')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Brier Score por grupo:\")\n",
    "print(brier_scores)\n",
    "\n",
    "# Validación de buena calibración\n",
    "threshold = 0.05  # Diferencia máxima aceptable (ajustable según el contexto)\n",
    "is_fair = np.abs(brier_scores.max() - brier_scores.min()) <= threshold\n",
    "\n",
    "if is_fair:\n",
    "    print(\"\\nEl modelo cumple con buena calibración.\")\n",
    "else:\n",
    "    print(\"\\nEl modelo NO cumple con buena calibración.\")\n",
    "    print(f\"Diferencia entre Brier Scores: {brier_scores.max() - brier_scores.min():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discriminación causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from econml.dml import CausalForestDML\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ejemplo de datos\n",
    "data = pd.DataFrame({\n",
    "    'gender': ['male', 'female', 'male', 'female', 'female', 'male', 'female', 'male', 'female', 'male'],\n",
    "    'age': [25, 30, 45, 35, 50, 40, 28, 60, 22, 27],  # Edad como variable no sensible\n",
    "    'education': [1, 2, 3, 2, 1, 1, 3, 2, 2, 3],  # Nivel educativo\n",
    "    'y_true': [1, 0, 1, 1, 0, 0, 1, 0, 0, 1],  # Etiquetas reales\n",
    "    'y_pred': [0.9, 0.1, 0.8, 0.7, 0.4, 0.3, 0.6, 0.2, 0.5, 0.9]  # Probabilidades predichas\n",
    "})\n",
    "\n",
    "# Separar las variables predictoras y la variable sensible\n",
    "X = data[['age', 'education']]  # Variables no sensibles\n",
    "T = data['gender']  # Atributo sensible (gender)\n",
    "y = data['y_true']  # Etiqueta\n",
    "\n",
    "# Entrenar un modelo con y_pred como la predicción\n",
    "model = LogisticRegression()\n",
    "X_train, X_test, y_train, y_test, T_train, T_test = train_test_split(X, y, T, test_size=0.3, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precisión del modelo sin considerar el atributo sensible: {accuracy:.2f}\")\n",
    "\n",
    "# Usamos CausalForestDML para analizar la causalidad y la discriminación\n",
    "cf = CausalForestDML(model_y=LogisticRegression(), model_t=LogisticRegression(), discrete_treatment=True)\n",
    "\n",
    "cf.fit(X_train, y_train, T_train)\n",
    "\n",
    "# Análisis de la discriminación causal - Predicción ajustada sin el atributo sensible\n",
    "y_pred_adjusted = cf.predict(X_test)\n",
    "\n",
    "# Comparación de las predicciones ajustadas con las originales\n",
    "print(f\"Precisión del modelo con ajuste causal: {accuracy_score(y_test, y_pred_adjusted):.2f}\")\n",
    "\n",
    "# Si la diferencia es significativa, hay discriminación causal\n",
    "discriminacion_causal = np.abs(accuracy - accuracy_score(y_test, y_pred_adjusted))\n",
    "\n",
    "threshold = 0.05  # Ajusta este umbral según el contexto\n",
    "if discriminacion_causal > threshold:\n",
    "    print(\"\\nEl modelo muestra discriminación causal.\")\n",
    "else:\n",
    "    print(\"\\nEl modelo no muestra discriminación causal.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Despliegue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo para despliegue\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "\n",
    "# Cargar y predecir con modelo desplegado\n",
    "model = joblib.load('best_model.pkl')\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pruebas A/B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "\n",
    "# Paso 1: Entrenar dos modelos\n",
    "# Modelo A (Base)\n",
    "model_a = RandomForestClassifier(random_state=42)\n",
    "model_a.fit(X_train, y_train)\n",
    "y_pred_a = model_a.predict(X_test)\n",
    "\n",
    "# Modelo B (Mejorado)\n",
    "model_b = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_b.fit(X_train, y_train)\n",
    "y_pred_b = model_b.predict(X_test)\n",
    "\n",
    "# Paso 2: Evaluar los modelos\n",
    "# (Cambia a las métricas correspondientes si es un problema de regresión)\n",
    "accuracy_a = accuracy_score(y_test, y_pred_a)\n",
    "accuracy_b = accuracy_score(y_test, y_pred_b)\n",
    "\n",
    "print(f\"Accuracy Modelo A: {accuracy_a}\")\n",
    "print(f\"Accuracy Modelo B: {accuracy_b}\")\n",
    "\n",
    "# Paso 3: Comparar predicciones (Prueba A/B)\n",
    "# Métrica para cada ejemplo individual\n",
    "errors_a = y_test != y_pred_a\n",
    "errors_b = y_test != y_pred_b\n",
    "\n",
    "# T-Test pareado (diferencias medias)\n",
    "t_stat, p_value = ttest_rel(errors_a, errors_b)\n",
    "print(f\"T-Test: t-statistic = {t_stat}, p-value = {p_value}\")\n",
    "\n",
    "# Prueba de Wilcoxon (no paramétrica)\n",
    "wilcoxon_stat, wilcoxon_p = wilcoxon(errors_a, errors_b)\n",
    "print(f\"Wilcoxon: stat = {wilcoxon_stat}, p-value = {wilcoxon_p}\")\n",
    "\n",
    "# Interpretación de resultados\n",
    "if p_value < 0.05:\n",
    "    print(\"La diferencia entre los modelos es estadísticamente significativa (T-Test).\")\n",
    "else:\n",
    "    print(\"No hay evidencia suficiente para afirmar que los modelos son diferentes (T-Test).\")\n",
    "\n",
    "if wilcoxon_p < 0.05:\n",
    "    print(\"La diferencia entre los modelos es estadísticamente significativa (Wilcoxon).\")\n",
    "else:\n",
    "    print(\"No hay evidencia suficiente para afirmar que los modelos son diferentes (Wilcoxon).\")\n",
    "\n",
    "# Paso 4: Visualizar diferencias en desempeño\n",
    "# Porcentaje de aciertos por modelo\n",
    "errors_a_mean = np.mean(errors_a)\n",
    "errors_b_mean = np.mean(errors_b)\n",
    "\n",
    "plt.bar(['Modelo A', 'Modelo B'], [1-errors_a_mean, 1-errors_b_mean])\n",
    "plt.ylabel('Proporción de aciertos')\n",
    "plt.title('Comparación entre modelos')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular errores absolutos en regresión\n",
    "errors_a = np.abs(y_test - model_a.predict(X_test))\n",
    "errors_b = np.abs(y_test - model_b.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supuestos de negocio\n",
    "income_per_correct_prediction = 100  # Ingreso por predicción correcta\n",
    "cost_per_error = 50  # Costo por predicción incorrecta\n",
    "model_cost = 10000  # Costo de desarrollo e implementación\n",
    "\n",
    "# Ingresos y costos del Modelo A\n",
    "correct_a = sum(y_test == y_pred_a)\n",
    "incorrect_a = sum(y_test != y_pred_a)\n",
    "income_a = correct_a * income_per_correct_prediction\n",
    "cost_a = incorrect_a * cost_per_error + model_cost\n",
    "roi_a = (income_a - cost_a) / model_cost\n",
    "\n",
    "# Ingresos y costos del Modelo B\n",
    "correct_b = sum(y_test == y_pred_b)\n",
    "incorrect_b = sum(y_test != y_pred_b)\n",
    "income_b = correct_b * income_per_correct_prediction\n",
    "cost_b = incorrect_b * cost_per_error + model_cost\n",
    "roi_b = (income_b - cost_b) / model_cost\n",
    "\n",
    "# Punto de Equilibrio para el Modelo Mejorado\n",
    "break_even_correct_predictions = model_cost / income_per_correct_prediction\n",
    "\n",
    "# Resultados\n",
    "print(f\"Modelo A - Ingreso: ${income_a}, Costo: ${cost_a}, ROI: {roi_a:.2f}\")\n",
    "print(f\"Modelo B - Ingreso: ${income_b}, Costo: ${cost_b}, ROI: {roi_b:.2f}\")\n",
    "print(f\"Punto de Equilibrio (Modelo Mejorado): {break_even_correct_predictions:.0f} predicciones correctas\")\n",
    "\n",
    "# Comparación Visual\n",
    "models = ['Modelo A', 'Modelo B']\n",
    "rois = [roi_a, roi_b]\n",
    "\n",
    "plt.bar(models, rois)\n",
    "plt.ylabel('ROI')\n",
    "plt.title('Comparación de ROI entre Modelos')\n",
    "plt.axhline(0, color='red', linestyle='--', label='Punto de Equilibrio')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
